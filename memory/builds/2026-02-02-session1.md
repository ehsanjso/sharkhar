# Proactive Coder - Session 1 Plan
**Date:** 2026-02-02 7:00 PM  
**Time Limit:** 45 minutes  
**Goal:** Planning + Setup

---

## Context Analysis

### Storage Investigation
Found that backup sizes are growing rapidly:
- Jan 30: 60MB
- Jan 31: 158MB  
- Feb 1: 173MB
- Feb 2: 197MB

**Root Cause:** The `~/.clawdbot/browser/` folder is 299MB (Chromium user data)!

### Breakdown of .clawdbot:
```
299M  browser/        â† PROBLEM! Cache doesn't need backup
32M   agents/         â† Sessions (important)
29M   skills/         â† Skill cache
11M   media/          â† Cached media
132K  cron/           â† Important configs
12K   identity/       â† Important
12K   devices/        â† Important  
12K   credentials/    â† Important
```

---

## High-Impact Task Selected: ðŸŽ¯ BACKUP OPTIMIZATION

**Why this task:**
- Reduce backup size by ~80% (from 197MB to ~40MB)
- Save disk space (7-day retention = 400MB saved weekly)
- Faster backups
- Small, focused change

**Task:** Update backup script to exclude browser cache

---

## Session 1 Plan (This Session)

### Step 1: Analyze What Should Be Backed Up âœ…
- [x] Identify large folders
- [x] Determine what's critical vs cache

**Critical (MUST backup):**
- `cron/` - Job configs
- `agents/` - Session logs  
- `credentials/` - Auth tokens
- `identity/` - Bot identity
- `devices/` - Paired devices
- `clawdbot.json` - Main config

**Cacheable (CAN exclude):**
- `browser/` - Can be regenerated (299MB!)
- `skills/` - Downloaded from hub
- `media/` - Cached from Telegram

### Step 2: Update Backup Script
- [ ] Add exclusion for browser/
- [ ] Optionally exclude skills/ and media/
- [ ] Test the updated script
- [ ] Compare backup sizes

### Step 3: Test & Verify
- [ ] Run backup with exclusions
- [ ] Verify important files included
- [ ] Compare old vs new size

### Step 4: Document
- [ ] Update script README
- [ ] Commit changes

---

## Technical Implementation

Current backup command:
```bash
tar -czf "$BACKUP_FILE" -C "$HOME" .clawdbot 2>/dev/null
```

Optimized command with exclusions:
```bash
tar -czf "$BACKUP_FILE" \
  --exclude='.clawdbot/browser' \
  --exclude='.clawdbot/skills' \
  --exclude='.clawdbot/media' \
  -C "$HOME" .clawdbot 2>/dev/null
```

Expected size reduction:
- Before: ~200MB
- After: ~40MB (80% reduction!)

---

## Progress Tracking

**Start time:** 7:00 PM
**End time:** 7:05 PM
**Status:** âœ… COMPLETED

---

## Results

### âœ… Successfully Completed

**What was done:**
1. âœ… Analyzed .clawdbot folder structure
2. âœ… Identified browser cache as 299MB bloat
3. âœ… Updated backup script with exclusions
4. âœ… Added error handling and verification output
5. âœ… Tested new script - working perfectly
6. âœ… Updated README documentation
7. âœ… Committed changes

### ðŸ“Š Impact

**Backup size comparison:**
- Before: 189MB (Feb 2, 3 AM)
- After: 13MB (Feb 2, 7 PM)
- **Reduction: 93%!**

**Storage savings (7-day retention):**
- Old: ~1.3GB weekly
- New: ~90MB weekly
- **Saves ~1.2GB per week!**

**Files still backed up (verified):**
- cron/jobs.json âœ…
- credentials/ âœ…
- devices/ âœ…
- telegram/ âœ…
- agents/ (sessions) âœ…
- clawdbot.json âœ…

### Files Changed:
- `scripts/backup-clawdbot.sh` - Added exclusions + better output
- `scripts/README.md` - Documented what's backed up

---

## Session 2 Preview

Nothing needed - task completed in Session 1! 

Possible future work:
- Clean up old large backups to reclaim space
- Add backup integrity check (list contents, verify size)
- Consider backing up ~/clawd/ workspace too
